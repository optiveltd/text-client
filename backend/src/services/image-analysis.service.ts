import { OpenAI } from 'openai';
import fs from 'fs/promises';
import path from 'path';
import { toFile } from 'openai/uploads';

export class ImageAnalysisService {
  private openai: OpenAI;

  constructor() {
    this.openai = new OpenAI({ 
      apiKey: process.env.OPENAI_API_KEY! 
    });
  }

  /**
   * × ×™×ª×•×— ×ª××•× ×” ×•×–×™×”×•×™ ×ª×•×›×Ÿ
   */
  async analyzeImage(imageFilePath: string): Promise<string> {
    try {
      console.log(`ğŸ–¼ï¸ Analyzing image: ${path.basename(imageFilePath)}`);

      // ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×§×™×™×
      await fs.access(imageFilePath);
      console.log(`âœ… Image file exists and is accessible`);

      // ×§×¨×™××ª ×”×ª××•× ×”
      const imageBuffer = await fs.readFile(imageFilePath);
      console.log(`âœ… Image file read: ${imageBuffer.length} bytes`);

      // ×™×¦×™×¨×ª File object
      const imageFile = await toFile(imageBuffer, path.basename(imageFilePath), {
        type: 'image/jpeg', // ××• 'image/png' ×‘×”×ª×× ×œ×¤×•×¨××˜
      });

      // ×©×œ×™×—×” ×œ-GPT-4 Vision
      console.log(`ğŸ¤– Calling OpenAI GPT-4 Vision API...`);
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `×ª××¨ ××ª ×”×ª××•× ×” ×”×–×• ×‘×¢×‘×¨×™×ª. ××” ××ª×” ×¨×•××”? ×ª×Ÿ ×ª×™××•×¨ ××¤×•×¨×˜ ×©×œ ×”×ª×•×›×Ÿ, ×”×¦×‘×¢×™×, ×”×¢×¦××™×, ×”×˜×§×¡×˜ (×× ×™×©), ×•×”××©××¢×•×ª ×”×›×œ×œ×™×ª.`
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:image/jpeg;base64,${imageBuffer.toString('base64')}`
                }
              }
            ]
          }
        ],
        max_tokens: 500,
        temperature: 0.7,
      });

      const analysis = response.choices[0]?.message?.content || '';
      
      if (!analysis || analysis.trim().length === 0) {
        throw new Error('Empty analysis response');
      }

      console.log(`âœ… Image analysis complete: "${analysis.substring(0, 50)}..."`);
      return analysis.trim();
    } catch (error: any) {
      console.error('âŒ Failed to analyze image:', {
        message: error?.message,
        status: error?.response?.status,
        data: error?.response?.data,
        stack: error?.stack
      });
      throw new Error(`Image analysis failed: ${error?.message || 'Unknown error'}`);
    }
  }

  /**
   * ×–×™×”×•×™ ×˜×§×¡×˜ ×‘×ª××•× ×” (OCR)
   */
  async extractTextFromImage(imageFilePath: string): Promise<string> {
    try {
      console.log(`ğŸ“ Extracting text from image: ${path.basename(imageFilePath)}`);

      const imageBuffer = await fs.readFile(imageFilePath);
      const imageFile = await toFile(imageBuffer, path.basename(imageFilePath), {
        type: 'image/jpeg',
      });

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `×§×¨× ××ª ×›×œ ×”×˜×§×¡×˜ ×©××•×¤×™×¢ ×‘×ª××•× ×” ×”×–×•. ×”×—×–×¨ ×¨×§ ××ª ×”×˜×§×¡×˜, ×œ×œ× ×”×¡×‘×¨×™× × ×•×¡×¤×™×. ×× ××™×Ÿ ×˜×§×¡×˜, ×›×ª×‘ "××™×Ÿ ×˜×§×¡×˜ ×‘×ª××•× ×”".`
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:image/jpeg;base64,${imageBuffer.toString('base64')}`
                }
              }
            ]
          }
        ],
        max_tokens: 300,
        temperature: 0.1,
      });

      const extractedText = response.choices[0]?.message?.content || '';
      console.log(`âœ… Text extracted: "${extractedText.substring(0, 50)}..."`);
      return extractedText.trim();
    } catch (error: any) {
      console.error('âŒ Failed to extract text from image:', error);
      throw new Error(`OCR failed: ${error?.message || 'Unknown error'}`);
    }
  }

  /**
   * × ×™×ª×•×— ×ª××•× ×” ×¢× ×”×§×©×¨ ×¢×¡×§×™
   */
  async analyzeImageForBusiness(imageFilePath: string, businessContext?: string): Promise<string> {
    try {
      console.log(`ğŸ’¼ Analyzing image for business context: ${path.basename(imageFilePath)}`);

      const imageBuffer = await fs.readFile(imageFilePath);
      const imageFile = await toFile(imageBuffer, path.basename(imageFilePath), {
        type: 'image/jpeg',
      });

      const contextPrompt = businessContext 
        ? `×”×§×©×¨ ×¢×¡×§×™: ${businessContext}\n\n`
        : '';

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `${contextPrompt}×ª××¨ ××ª ×”×ª××•× ×” ×”×–×• ×‘×¢×‘×¨×™×ª. ×”×ª××§×“ ×‘×ª×•×›×Ÿ ×”×¨×œ×•×•× ×˜×™ ×œ×¢×¡×§×™×, ×©×™×•×•×§, ××• ×©×™×¨×•×ª×™×. ×× ×™×© ×˜×§×¡×˜ ×‘×ª××•× ×”, ×§×¨× ××•×ª×•. ×× ×™×© ×œ×•×’×• ××• ××•×ª×’, ×–×”×” ××•×ª×•. ×ª×Ÿ ×”××œ×¦×•×ª ××• ×ª×•×‘× ×•×ª ×¨×œ×•×•× ×˜×™×•×ª.`
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:image/jpeg;base64,${imageBuffer.toString('base64')}`
                }
              }
            ]
          }
        ],
        max_tokens: 600,
        temperature: 0.7,
      });

      const businessAnalysis = response.choices[0]?.message?.content || '';
      console.log(`âœ… Business analysis complete: "${businessAnalysis.substring(0, 50)}..."`);
      return businessAnalysis.trim();
    } catch (error: any) {
      console.error('âŒ Failed to analyze image for business:', error);
      throw new Error(`Business image analysis failed: ${error?.message || 'Unknown error'}`);
    }
  }
}


