import OpenAI from 'openai';
import { config } from '../config/env.js';
import { AIResponse, AIConfig, Message } from '../types/index.js';
import { SupabaseService } from './supabase.service.js';

export class AIService {
  private openai: OpenAI;
  private defaultConfig: AIConfig;
  private supabaseService: SupabaseService;

  constructor() {
    if (!config.openai.apiKey) {
      throw new Error('OPENAI_API_KEY is required but not found in environment variables');
    }
    this.openai = new OpenAI({
      apiKey: config.openai.apiKey,
    });
    this.supabaseService = new SupabaseService();
    
    this.defaultConfig = {
      model: config.openai.model,
      temperature: 0.3,
      maxTokens: 1000,
      systemPrompt: '××ª×” ×¡×•×›× ×ª AI ×—×›××” ×•××•×¢×™×œ×”. ×¢× ×” ×‘×¢×‘×¨×™×ª ×‘×¦×•×¨×” ×‘×¨×•×¨×” ×•×™×“×™×“×•×ª×™×ª. - ×ª×©××¨×™ ×¢×œ ×–×¨×™××” ×˜×‘×¢×™×ª, ×‘×œ×™ ×œ×—×–×•×¨ ×¢×œ ×¢×¦××š.\n' +
          '- ×× ×”×œ×§×•×— ×§×¦×¨ â€“ ×ª×¢× ×™ ×‘×§×¦×¨×”. ×× ××¤×•×¨×˜ â€“ ×ª×ª××™××™ ××ª ×¢×¦××š.\n' +
          '- ×× ×›×‘×¨ ×™×© ×¤×¨×˜×™× ×¢×œ×™×•, ×ª×©×ª××©×™ ×‘×”×.\n' +
          '- ×× ×”×•× ××ª× ×’×“ â€“ ×ª×ª×™×™×—×¡×™ ×‘×¢×“×™× ×•×ª ×•××œ ×ª×™×œ×—×¦×™ ×œ××›×•×¨.\n' +
          '- ×ª××™×“ ×ª×©××¨×™ ×¢×œ ×©×¤×” ×× ×•×©×™×ª, ×§×œ×™×œ×” ×•××–××™× ×”.\n' +
          '- ×œ×©××•×œ ×¨×§ ×©××œ×” ××—×ª ×‘×›×œ ×”×•×“×¢×” \n' +
          '- ×œ×¢× ×•×ª ×¢×“ 150 ×ª×•×•×™× ×›×•×œ×œ ×¨×•×•×—×™×\n' +
          '- ××™×Ÿ ×œ×—×¨×•×’ ××”×’×‘×œ×” ×–×• ×‘×©×•× ××§×¨×”\n' +
          '- ×× ×”×ª×’×•×‘×” ××¨×•×›×” ××“×™, ×§×™×¦×¨ ××•×ª×”\n' +
          '- ×ª××™×“ ×¡×¤×•×¨ ××ª ×”×ª×•×•×™× ×œ×¤× ×™ ×”×©×œ×™×—×”\n' +
          '- ×”×©×ª××© ×‘× ×§×•×“×•×ª ×¢×¦×™×¨×” ×˜×‘×¢×™×•×ª (× ×§×•×“×”, ×¡×™××Ÿ ×©××œ×”)\n' +
          '- ×”×™×× ×¢ ×××©×¤×˜×™× ××¨×•×›×™× ××“×™'
    };
  }

  async transcribeWav(filePath: string): Promise<string> {
    try {
      const file = await (await import('fs')).promises.readFile(filePath);
      const response = await this.openai.audio.transcriptions.create({
        file: new File([file], 'audio.wav', { type: 'audio/wav' }) as any,
        model: 'whisper-1',
        language: 'he',
        response_format: 'text',
      } as any);
      // Some SDKs return string directly when response_format=text
      return typeof response === 'string' ? response : (response as any).text || '';
    } catch (e) {
      console.error('Transcription failed:', e);
      throw new Error('Failed to transcribe audio');
    }
  }

  async generateResponse(
    messages: Message[],
    customConfig?: Partial<AIConfig>,
    isForWhatsApp: boolean = false
  ): Promise<AIResponse> {
    try {
      const aiConfig = { ...this.defaultConfig, ...customConfig };
      
      // Resolve system prompt: prefer custom; otherwise internal fallback
      let systemPromptToUse = (aiConfig.systemPrompt && typeof aiConfig.systemPrompt === 'string' && aiConfig.systemPrompt.trim().length > 0)
        ? aiConfig.systemPrompt.trim()
        : '';

      if (!systemPromptToUse) {
        systemPromptToUse = this.defaultConfig.systemPrompt;
      }

      // Load global guardrails and prepend to system prompt
      let guardrails = '';
      try {
        // Lazy import to avoid bundler path issues
        // eslint-disable-next-line @typescript-eslint/no-var-requires
        const fs = require('fs');
        // eslint-disable-next-line @typescript-eslint/no-var-requires
        const path = require('path');
        const filePath = path.resolve(__dirname, '..', 'assets', 'global-guardrails.txt');
        if (fs.existsSync(filePath)) {
          guardrails = fs.readFileSync(filePath, 'utf8');
        }
      } catch {}

      // Add behavioral guidelines directly in code
      const behavioralGuidelines = `
========================
ğŸ¤– ×›×œ×œ×™ ×‘×™× ×” - ×”×ª× ×”×’×•×ª
========================
- ×ª×©××¨×™ ×¢×œ ×–×¨×™××” ×˜×‘×¢×™×ª ×•×©×¤×” ×× ×•×©×™×ª.
- ×ª×©××œ×™ ×©××œ×” ××—×ª ×‘×›×œ ×”×•×“×¢×” ×‘×œ×‘×“.
- ××œ ×ª×—×–×¨×™ ×¢×œ ×¢×¦××š ×•××œ ×ª××”×¨×™ ×œ××›×•×¨.
- ×× ×”×œ×§×•×— ×§×¦×¨ â€“ ×ª×¢× ×™ ×‘×§×¦×¨×”. ×× ××¤×•×¨×˜ â€“ ×ª×–×¨××™ ××™×ª×•.
- ×©××¨×™ ×¢×œ ××™×–×•×Ÿ ×‘×™×Ÿ ×”×•××•×¨ ×§×œ×™×œ ×œ××§×¦×•×¢×™×•×ª.
- ×× × ×“×¨×©×ª ×”×‘×”×¨×”, ×”×©×ª××©×™ ×‘×©× ×”×œ×§×•×—.
- ×ª××™×“ ×ª×©××¨×™ ×¢×œ ××•×•×™×¨×” ××–××™× ×”, ×¢× ×‘×™×˜×—×•×Ÿ ×•×××¤×ª×™×”.
- **×—×©×•×‘ ×××•×“: ×× ×”×œ×§×•×— ×©×œ×— ××¡×¤×¨ ×”×•×“×¢×•×ª - ×¢× ×™ ×¢×œ ×›×•×œ×Ÿ ×‘×”×•×“×¢×” ××—×ª ×‘×œ×‘×“!**
- **××œ ×ª×©×œ×—×™ ××¡×¤×¨ ×”×•×“×¢×•×ª × ×¤×¨×“×•×ª - ×ª××™×“ ×”×•×“×¢×” ××—×ª ××§×™×¤×” ×œ×›×œ ××” ×©×”×œ×§×•×— ×›×ª×‘**
========================`;

      const combinedSystem = guardrails
        ? `${behavioralGuidelines}\n\n${guardrails}\n\n${systemPromptToUse}`
        : `${behavioralGuidelines}\n\n${systemPromptToUse}`;

      // Convert messages to OpenAI format and inject combined system prompt
      const openaiMessages: { role: 'system' | 'user' | 'assistant'; content: string }[] = [];
      openaiMessages.push({ role: 'system', content: combinedSystem });

      openaiMessages.push(
        ...messages.map(msg => ({
          role: msg.role as 'user' | 'assistant' | 'system',
          content: msg.content
        }))
      );

      // ×”×•×¡×¤×ª ×”×’×‘×œ×ª ×ª×•×•×™× ×œ-system prompt ×¨×§ ×¢×‘×•×¨ WhatsApp
      if (isForWhatsApp) {
        const systemPromptWithLimits = `${combinedSystem}

**×—×•×§×™× ×—×©×•×‘×™× ×œ×ª×’×•×‘×”:**
- ×”×ª×’×•×‘×” ×—×™×™×‘×ª ×œ×”×™×•×ª ×§×¦×¨×” ×•××“×•×™×§×ª
- ××§×¡×™××•× 150 ×ª×•×•×™× ×›×•×œ×œ ×¨×•×•×—×™×
- ××™×Ÿ ×œ×—×¨×•×’ ××”×’×‘×œ×” ×–×• ×‘×©×•× ××§×¨×”
- ×× ×”×ª×’×•×‘×” ××¨×•×›×” ××“×™, ×§×™×¦×¨ ××•×ª×”
- ×ª××™×“ ×¡×¤×•×¨ ××ª ×”×ª×•×•×™× ×œ×¤× ×™ ×”×©×œ×™×—×”`;

        // ×¢×“×›×•×Ÿ ×”-system message ×¢× ×”×’×‘×œ×•×ª
        openaiMessages[0].content = systemPromptWithLimits;
      }

      // Add thinking delay for smarter responses
      await new Promise(resolve => setTimeout(resolve, 4000));

      const completion = await this.openai.chat.completions.create({
        model: aiConfig.model,
        messages: openaiMessages,
        temperature: aiConfig.temperature,
        max_tokens: aiConfig.maxTokens,
      });

      const response = completion.choices[0]?.message?.content || '';
      const usage = completion.usage;
      
      // ×‘×“×™×§×” × ×•×¡×¤×ª ×©×œ ××•×¨×š ×”×ª×’×•×‘×” ×¨×§ ×¢×‘×•×¨ WhatsApp
      const validatedResponse = isForWhatsApp ? this.validateResponseLength(response) : response;

      return {
        content: validatedResponse,
        usage: usage ? {
          promptTokens: usage.prompt_tokens,
          completionTokens: usage.completion_tokens,
          totalTokens: usage.total_tokens
        } : undefined
      };
    } catch (error) {
      console.error('Error generating AI response:', error);
      throw new Error('Failed to generate AI response');
    }
  }

  /**
   * ×‘×“×™×§×” ×•×ª×™×§×•×Ÿ ××•×¨×š ×”×ª×’×•×‘×”
   */
  private validateResponseLength(response: string): string {
    const maxLength = 150;
    
    if (response.length <= maxLength) {
      return response;
    }

    // ×§×™×¦×•×¨ ×”×ª×’×•×‘×”
    let shortenedResponse = response.substring(0, maxLength - 3) + '...';
    
    // × ×¡×” ×œ××¦×•× × ×§×•×“×ª ×¢×¦×™×¨×” ×˜×‘×¢×™×ª
    const lastSpace = shortenedResponse.lastIndexOf(' ');
    if (lastSpace > maxLength * 0.8) { // ×× ×™×© ×¨×•×•×— ×§×¨×•×‘ ×œ×¡×•×£
      shortenedResponse = response.substring(0, lastSpace) + '...';
    }

    console.warn(`âš ï¸ Response truncated from ${response.length} to ${shortenedResponse.length} characters`);
    return shortenedResponse;
  }

  async generateSystemPrompt(prompt: string): Promise<string> {
    try {
      const completion = await this.openai.chat.completions.create({
        model: this.defaultConfig.model,
        messages: [
          {
            role: 'system',
            content: '××ª×” ×¢×•×–×¨ ×œ×™×¦×•×¨ system prompts ×™×¢×™×œ×™×. ×¢× ×” ×‘×¢×‘×¨×™×ª.'
          },
          {
            role: 'user',
            content: `×¦×•×¨ system prompt ×¢×‘×•×¨: ${prompt}`
          }
        ],
        temperature: 0.3,
        max_tokens: 500,
      });

      return completion.choices[0]?.message?.content || '';
    } catch (error) {
      console.error('Error generating system prompt:', error);
      throw new Error('Failed to generate system prompt');
    }
  }
}


